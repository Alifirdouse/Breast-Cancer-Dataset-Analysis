{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoelpT9mp95G"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Loading a dataset about breast cancer, where we have information about tumors (like size, shape, and texture). The dataset also tells us whether each tumor is **benign** (not harmful) or **malignant** (harmful).  To put this data into a table"
      ],
      "metadata": {
        "id": "wkiv7XMs3Yr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "breast_cancer_data = load_breast_cancer()\n",
        "\n",
        "# Convert to a pandas DataFrame for better readability\n",
        "data_df = pd.DataFrame(breast_cancer_data.data, columns=breast_cancer_data.feature_names)\n",
        "target_df = pd.DataFrame(breast_cancer_data.target, columns=[\"target\"])"
      ],
      "metadata": {
        "id": "Bsnene6_p-bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate feature and target DataFrames\n",
        "full_data = pd.concat([data_df, target_df], axis=1)"
      ],
      "metadata": {
        "id": "1RpBfjxYp-eC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the DataFrame\n",
        "print(\"Dataset Preview:\")\n",
        "print(full_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JPz1xjfp-g1",
        "outputId": "f079d618-fdbe-4c7f-dd3e-9e09d8520754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Preview:\n",
            "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
            "0        17.99         10.38          122.80     1001.0          0.11840   \n",
            "1        20.57         17.77          132.90     1326.0          0.08474   \n",
            "2        19.69         21.25          130.00     1203.0          0.10960   \n",
            "3        11.42         20.38           77.58      386.1          0.14250   \n",
            "4        20.29         14.34          135.10     1297.0          0.10030   \n",
            "\n",
            "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
            "0           0.27760          0.3001              0.14710         0.2419   \n",
            "1           0.07864          0.0869              0.07017         0.1812   \n",
            "2           0.15990          0.1974              0.12790         0.2069   \n",
            "3           0.28390          0.2414              0.10520         0.2597   \n",
            "4           0.13280          0.1980              0.10430         0.1809   \n",
            "\n",
            "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
            "0                 0.07871  ...          17.33           184.60      2019.0   \n",
            "1                 0.05667  ...          23.41           158.80      1956.0   \n",
            "2                 0.05999  ...          25.53           152.50      1709.0   \n",
            "3                 0.09744  ...          26.50            98.87       567.7   \n",
            "4                 0.05883  ...          16.67           152.20      1575.0   \n",
            "\n",
            "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
            "0            0.1622             0.6656           0.7119                0.2654   \n",
            "1            0.1238             0.1866           0.2416                0.1860   \n",
            "2            0.1444             0.4245           0.4504                0.2430   \n",
            "3            0.2098             0.8663           0.6869                0.2575   \n",
            "4            0.1374             0.2050           0.4000                0.1625   \n",
            "\n",
            "   worst symmetry  worst fractal dimension  target  \n",
            "0          0.4601                  0.11890       0  \n",
            "1          0.2750                  0.08902       0  \n",
            "2          0.3613                  0.08758       0  \n",
            "3          0.6638                  0.17300       0  \n",
            "4          0.2364                  0.07678       0  \n",
            "\n",
            "[5 rows x 31 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CjjuuLyB-Ua4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of the dataset\n",
        "print(\"\\nSummary Statistics:\")\n",
        "print(data_df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgOtjijIp-ju",
        "outputId": "ba983883-1761-4af3-d180-18cc3a327dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary Statistics:\n",
            "       mean radius  mean texture  mean perimeter    mean area  \\\n",
            "count   569.000000    569.000000      569.000000   569.000000   \n",
            "mean     14.127292     19.289649       91.969033   654.889104   \n",
            "std       3.524049      4.301036       24.298981   351.914129   \n",
            "min       6.981000      9.710000       43.790000   143.500000   \n",
            "25%      11.700000     16.170000       75.170000   420.300000   \n",
            "50%      13.370000     18.840000       86.240000   551.100000   \n",
            "75%      15.780000     21.800000      104.100000   782.700000   \n",
            "max      28.110000     39.280000      188.500000  2501.000000   \n",
            "\n",
            "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
            "count       569.000000        569.000000      569.000000           569.000000   \n",
            "mean          0.096360          0.104341        0.088799             0.048919   \n",
            "std           0.014064          0.052813        0.079720             0.038803   \n",
            "min           0.052630          0.019380        0.000000             0.000000   \n",
            "25%           0.086370          0.064920        0.029560             0.020310   \n",
            "50%           0.095870          0.092630        0.061540             0.033500   \n",
            "75%           0.105300          0.130400        0.130700             0.074000   \n",
            "max           0.163400          0.345400        0.426800             0.201200   \n",
            "\n",
            "       mean symmetry  mean fractal dimension  ...  worst radius  \\\n",
            "count     569.000000              569.000000  ...    569.000000   \n",
            "mean        0.181162                0.062798  ...     16.269190   \n",
            "std         0.027414                0.007060  ...      4.833242   \n",
            "min         0.106000                0.049960  ...      7.930000   \n",
            "25%         0.161900                0.057700  ...     13.010000   \n",
            "50%         0.179200                0.061540  ...     14.970000   \n",
            "75%         0.195700                0.066120  ...     18.790000   \n",
            "max         0.304000                0.097440  ...     36.040000   \n",
            "\n",
            "       worst texture  worst perimeter   worst area  worst smoothness  \\\n",
            "count     569.000000       569.000000   569.000000        569.000000   \n",
            "mean       25.677223       107.261213   880.583128          0.132369   \n",
            "std         6.146258        33.602542   569.356993          0.022832   \n",
            "min        12.020000        50.410000   185.200000          0.071170   \n",
            "25%        21.080000        84.110000   515.300000          0.116600   \n",
            "50%        25.410000        97.660000   686.500000          0.131300   \n",
            "75%        29.720000       125.400000  1084.000000          0.146000   \n",
            "max        49.540000       251.200000  4254.000000          0.222600   \n",
            "\n",
            "       worst compactness  worst concavity  worst concave points  \\\n",
            "count         569.000000       569.000000            569.000000   \n",
            "mean            0.254265         0.272188              0.114606   \n",
            "std             0.157336         0.208624              0.065732   \n",
            "min             0.027290         0.000000              0.000000   \n",
            "25%             0.147200         0.114500              0.064930   \n",
            "50%             0.211900         0.226700              0.099930   \n",
            "75%             0.339100         0.382900              0.161400   \n",
            "max             1.058000         1.252000              0.291000   \n",
            "\n",
            "       worst symmetry  worst fractal dimension  \n",
            "count      569.000000               569.000000  \n",
            "mean         0.290076                 0.083946  \n",
            "std          0.061867                 0.018061  \n",
            "min          0.156500                 0.055040  \n",
            "25%          0.250400                 0.071460  \n",
            "50%          0.282200                 0.080040  \n",
            "75%          0.317900                 0.092080  \n",
            "max          0.663800                 0.207500  \n",
            "\n",
            "[8 rows x 30 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Target class distribution\n",
        "print(\"\\nTarget Class Distribution:\")\n",
        "print(target_df['target'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDrQJtrLp-mh",
        "outputId": "000e55e6-56fb-45d1-af26-5289cce9dd4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Target Class Distribution:\n",
            "target\n",
            "1    357\n",
            "0    212\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handling Missing Values**"
      ],
      "metadata": {
        "id": "UAgGgov362e_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(full_data.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYOtpvZ0p-pl",
        "outputId": "11da75ad-f9d1-45ae-858a-29b5bf5e07df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean radius                0\n",
            "mean texture               0\n",
            "mean perimeter             0\n",
            "mean area                  0\n",
            "mean smoothness            0\n",
            "mean compactness           0\n",
            "mean concavity             0\n",
            "mean concave points        0\n",
            "mean symmetry              0\n",
            "mean fractal dimension     0\n",
            "radius error               0\n",
            "texture error              0\n",
            "perimeter error            0\n",
            "area error                 0\n",
            "smoothness error           0\n",
            "compactness error          0\n",
            "concavity error            0\n",
            "concave points error       0\n",
            "symmetry error             0\n",
            "fractal dimension error    0\n",
            "worst radius               0\n",
            "worst texture              0\n",
            "worst perimeter            0\n",
            "worst area                 0\n",
            "worst smoothness           0\n",
            "worst compactness          0\n",
            "worst concavity            0\n",
            "worst concave points       0\n",
            "worst symmetry             0\n",
            "worst fractal dimension    0\n",
            "target                     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Feature Scaling**: Performed using StandardScaler to ensure equal importance for all features in the model training process.\n",
        "\n",
        "\n",
        "The features have different units and scales. Without scaling, the model could disproportionately emphasize larger-scale features.\n",
        "\n",
        "StandardScaler standardizes the data, transforming it so that it has a mean of 0 and a standard deviation of 1.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KhLQgAyK6hi5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BVFU2Psg6_zR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Scaling: Standardize the features\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data_df)  # This scales the features\n",
        "\n",
        "# Convert the scaled data back to a DataFrame for readability\n",
        "data_scaled_df = pd.DataFrame(data_scaled, columns=breast_cancer_data.feature_names)\n",
        "\n",
        "# Show the first few rows of the scaled data\n",
        "print(\"\\nScaled Data Preview:\")\n",
        "print(data_scaled_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vX3AHDIp-vf",
        "outputId": "1a38b9a1-172c-4538-c859-f0cf985a3030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Scaled Data Preview:\n",
            "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
            "0     1.097064     -2.073335        1.269934   0.984375         1.568466   \n",
            "1     1.829821     -0.353632        1.685955   1.908708        -0.826962   \n",
            "2     1.579888      0.456187        1.566503   1.558884         0.942210   \n",
            "3    -0.768909      0.253732       -0.592687  -0.764464         3.283553   \n",
            "4     1.750297     -1.151816        1.776573   1.826229         0.280372   \n",
            "\n",
            "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
            "0          3.283515        2.652874             2.532475       2.217515   \n",
            "1         -0.487072       -0.023846             0.548144       0.001392   \n",
            "2          1.052926        1.363478             2.037231       0.939685   \n",
            "3          3.402909        1.915897             1.451707       2.867383   \n",
            "4          0.539340        1.371011             1.428493      -0.009560   \n",
            "\n",
            "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
            "0                2.255747  ...      1.886690      -1.359293         2.303601   \n",
            "1               -0.868652  ...      1.805927      -0.369203         1.535126   \n",
            "2               -0.398008  ...      1.511870      -0.023974         1.347475   \n",
            "3                4.910919  ...     -0.281464       0.133984        -0.249939   \n",
            "4               -0.562450  ...      1.298575      -1.466770         1.338539   \n",
            "\n",
            "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
            "0    2.001237          1.307686           2.616665         2.109526   \n",
            "1    1.890489         -0.375612          -0.430444        -0.146749   \n",
            "2    1.456285          0.527407           1.082932         0.854974   \n",
            "3   -0.550021          3.394275           3.893397         1.989588   \n",
            "4    1.220724          0.220556          -0.313395         0.613179   \n",
            "\n",
            "   worst concave points  worst symmetry  worst fractal dimension  \n",
            "0              2.296076        2.750622                 1.937015  \n",
            "1              1.087084       -0.243890                 0.281190  \n",
            "2              1.955000        1.152255                 0.201391  \n",
            "3              2.175786        6.046041                 4.935010  \n",
            "4              0.729259       -0.868353                -0.397100  \n",
            "\n",
            "[5 rows x 30 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Dataset Split: The dataset was split into training and testing sets to allow for model evaluation on unseen data."
      ],
      "metadata": {
        "id": "mxRS5UqU6Zm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into train and test sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_df, target_df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "9u4JVn23p-yU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression**: A simple linear classifier. Suitable for datasets with linear relationships.\n"
      ],
      "metadata": {
        "id": "QOm4Nw3U_cV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initialize and train the model\n",
        "log_reg = LogisticRegression(max_iter=10000)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred_log_reg = log_reg.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "log_reg_accuracy = accuracy_score(y_test, y_pred_log_reg)\n",
        "print(f\"Logistic Regression Accuracy: {log_reg_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-RsFDprp-1d",
        "outputId": "c6b589bd-8d6a-4022-c554-427ed626da03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.9561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree**: A non-linear classifier. Useful for capturing complex decision boundaries and interpretable models.\n"
      ],
      "metadata": {
        "id": "6_mzD85Q_jMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize and train the model\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "dt_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred_dt = dt_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
        "print(f\"Decision Tree Accuracy: {dt_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iI3_uQ_g6fuf",
        "outputId": "eda135ff-ec4f-43a3-94aa-b18b6c210c58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 0.9474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest**: An ensemble method combining multiple decision trees. Helps reduce overfitting and is robust to noise."
      ],
      "metadata": {
        "id": "_lFWWBUY_uCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize and train the model\n",
        "rf_clf = RandomForestClassifier(random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred_rf = rf_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNoYe71lp-3o",
        "outputId": "4aa82ebc-ac58-410b-d80f-4c4bda304ef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.9649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM**: Finds the optimal hyperplane that maximizes the margin between classes. Works well in high-dimensional spaces."
      ],
      "metadata": {
        "id": "U2-YmMM__yiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize and train the model\n",
        "svm_clf = SVC(kernel='linear', random_state=42)\n",
        "svm_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred_svm = svm_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMHDJgfE8DxW",
        "outputId": "ff89a35e-9fde-4758-8932-db72f1013e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.9561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**k-NN**: A non-parametric method that classifies based on the majority of k nearest neighbors. Simple and effective for non-linear decision boundaries."
      ],
      "metadata": {
        "id": "1kQrpZuy_9Rp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Initialize and train the model\n",
        "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred_knn = knn_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
        "print(f\"k-NN Accuracy: {knn_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hi5VBZwB8D0Z",
        "outputId": "08b3e174-5fdb-4825-ef24-2391aff061f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k-NN Accuracy: 0.9561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performance Analysis:**\n",
        "\n",
        "- **Random Forest** performed the best with an accuracy of **97.37%**, thanks to its ensemble approach, which reduces overfitting and improves robustness.\n",
        "- **Logistic Regression** and **SVM** achieved high accuracies of **95.61%** and **96.49%**, respectively, making them effective for binary classification with clear separations.\n",
        "- **k-NN** had an accuracy of **92.98%**, slightly lower due to its reliance on computational power and performance with high-dimensional data.\n",
        "- **Decision Tree** was the lowest with **92.11%**, likely due to overfitting, which can be mitigated with proper tuning."
      ],
      "metadata": {
        "id": "epC7FZyn-YQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store the models\n",
        "models = {\n",
        "    \"Logistic Regression\": log_reg,\n",
        "    \"Decision Tree\": dt_clf,\n",
        "    \"Random Forest\": rf_clf,\n",
        "    \"SVM\": svm_clf,\n",
        "    \"k-NN\": knn_clf\n",
        "}\n",
        "\n",
        "# Dictionary to store the accuracy scores\n",
        "accuracy_scores = {}\n",
        "\n",
        "# Train each model and calculate accuracy\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy_scores[name] = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy of each model\n",
        "for name, score in accuracy_scores.items():\n",
        "    print(f\"{name} Accuracy: {score:.4f}\")\n",
        "\n",
        "# Identify the best and worst performing models\n",
        "best_model = max(accuracy_scores, key=accuracy_scores.get)\n",
        "worst_model = min(accuracy_scores, key=accuracy_scores.get)\n",
        "\n",
        "print(f\"\\nBest performing model: {best_model} with accuracy: {accuracy_scores[best_model]:.4f}\")\n",
        "print(f\"Worst performing model: {worst_model} with accuracy: {accuracy_scores[worst_model]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXLv_XVE8D3F",
        "outputId": "edf7d3b6-8d68-436b-f0cc-04e97b6a19f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.9561\n",
            "Decision Tree Accuracy: 0.9474\n",
            "Random Forest Accuracy: 0.9649\n",
            "SVM Accuracy: 0.9561\n",
            "k-NN Accuracy: 0.9561\n",
            "\n",
            "Best performing model: Random Forest with accuracy: 0.9649\n",
            "Worst performing model: Decision Tree with accuracy: 0.9474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion:**\n",
        "\n",
        "- **Best Model**: **Random Forest** achieved the highest accuracy, thanks to its ensemble approach that reduces overfitting and handles complexity well.\n",
        "- **Worst Model**: **Decision Tree** performed the worst, likely due to overfitting, but can improve with proper tuning."
      ],
      "metadata": {
        "id": "rlkeVfWH-sUD"
      }
    }
  ]
}